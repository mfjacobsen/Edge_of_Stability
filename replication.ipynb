{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73471422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ded979",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 5000\n",
    "NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3ef949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0249c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Normalize images\n",
    "all_images = torch.stack([dataset[i][0] for i in range(len(dataset))])\n",
    "all_labels = torch.tensor([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "cifar10_mean = np.array(all_images.mean(dim=(0, 2, 3)))\n",
    "cifar10_std = np.array(all_images.std(dim=(0, 2, 3)))\n",
    "\n",
    "mean_tensor = torch.tensor(cifar10_mean).view(1, 3, 1, 1)\n",
    "std_tensor = torch.tensor(cifar10_std).view(1, 3, 1, 1)\n",
    "\n",
    "normalized_images = (all_images - mean_tensor) / std_tensor\n",
    "\n",
    "# Subset first 5k samples\n",
    "images = normalized_images[:SAMPLE_SIZE]  # Use normalized images\n",
    "subset_labels = all_labels[:SAMPLE_SIZE]\n",
    "\n",
    "# Convert labels to one-hot encoding for MSE loss (CIFAR-10 has 10 classes)\n",
    "labels = torch.zeros(subset_labels.size(0), NUM_LABELS, device=subset_labels.device)\n",
    "labels.scatter_(1, subset_labels.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8b0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_1_size, hidden_layer_2_size, num_labels):\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, hidden_layer_1_size, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_layer_1_size, hidden_layer_2_size, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_layer_2_size, num_labels, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b928394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sharpness(model, criterion, images, labels,\n",
    "                      iters: int = 20, tol: float = 1e-3,\n",
    "                      subsample: int | None = 1024, damping: float = 0.0) -> float:\n",
    "    \"\"\"\n",
    "    Estimates λ_max(H) (sharpness) of the loss at current model parameters via\n",
    "    power iteration with Hessian–vector products (Pearlmutter trick).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model      : nn.Module (params require_grad=True)\n",
    "    criterion  : callable(logits, targets) -> scalar loss (mean reduction)\n",
    "    images     : tensor [N, ...] on correct device\n",
    "    labels     : tensor [N] on correct device\n",
    "    iters      : power-iteration steps (15–25 typical)\n",
    "    tol        : relative convergence tolerance\n",
    "    subsample  : if not None, randomly sample this many examples for speed\n",
    "    damping    : computes eigenvalues of (H + damping * I)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: estimated largest eigenvalue (sharpness)\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()  # stabilize stats (esp. BN/Dropout)\n",
    "\n",
    "    # ---- choose subset (for speed/memory) ----\n",
    "    if subsample is not None and images.size(0) > subsample:\n",
    "        idx = torch.randperm(images.size(0), device=images.device)[:subsample]\n",
    "        xb, yb = images[idx], labels[idx]\n",
    "    else:\n",
    "        xb, yb = images, labels\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    n = sum(p.numel() for p in params)\n",
    "    if n == 0:\n",
    "        if was_training: model.train()\n",
    "        return 0.0\n",
    "\n",
    "    # ---- forward with graph for second-order autodiff ----\n",
    "    # Important: no torch.no_grad() here\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    logits = model(xb)\n",
    "    loss = criterion(logits, yb)\n",
    "\n",
    "    # ∇ℓ with graph so we can differentiate it again\n",
    "    grads = torch.autograd.grad(loss, params, create_graph=True, retain_graph=True)\n",
    "    g_flat = torch.cat([gi.reshape(-1) for gi in grads])\n",
    "\n",
    "    # init v ~ unit vector\n",
    "    with torch.no_grad():\n",
    "        v = torch.randn(n, device=g_flat.device)\n",
    "        v /= (v.norm() + 1e-12)\n",
    "\n",
    "    lam_prev = None\n",
    "    for _ in range(iters):\n",
    "        # H v = ∇[(∇ℓ)·v]\n",
    "        gv = (g_flat * v).sum()\n",
    "        Hv_parts = torch.autograd.grad(gv, params, retain_graph=True)\n",
    "        Hv = torch.cat([h.reshape(-1) for h in Hv_parts])\n",
    "        if damping != 0.0:\n",
    "            Hv = Hv + damping * v\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Hv_norm = Hv.norm()\n",
    "            if Hv_norm == 0 or torch.isnan(Hv_norm):\n",
    "                lam = 0.0\n",
    "                break\n",
    "            v = Hv / (Hv_norm + 1e-12)\n",
    "            lam = torch.dot(v, Hv).item()\n",
    "\n",
    "            if lam_prev is not None:\n",
    "                if abs(lam - lam_prev) / (abs(lam_prev) + 1e-12) < tol:\n",
    "                    break\n",
    "            lam_prev = lam\n",
    "\n",
    "    # cleanup and restore mode\n",
    "    del grads, g_flat, logits, loss\n",
    "    if was_training: model.train()\n",
    "    return float(lam_prev if lam_prev is not None else lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314e88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_output_files(output_dir=\"output\"): \n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "    output_data_path = os.path.join(output_dir, \"output.csv\")\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "            metadata = pd.read_csv(metadata_path)\n",
    "    else:\n",
    "        metadata = pd.DataFrame({\n",
    "            \"model_id\": pd.Series(dtype=\"int\"),\n",
    "            \"model_type\": pd.Series(dtype=\"str\"),\n",
    "            \"optimizer\": pd.Series(dtype=\"str\"),\n",
    "            \"learning_rate\": pd.Series(dtype=\"float\"),\n",
    "            \"num_epochs\": pd.Series(dtype=\"int\"),\n",
    "            \"train_time\": pd.Series(dtype=\"float\")\n",
    "        })\n",
    "\n",
    "    if os.path.exists(output_data_path):\n",
    "        output_data = pd.read_csv(output_data_path)\n",
    "    else:\n",
    "        output_data = pd.DataFrame({\n",
    "            \"model_id\": pd.Series(dtype=\"int\"),\n",
    "            \"loss\": pd.Series(dtype=\"float\"),\n",
    "            \"sharpness\": pd.Series(dtype=\"float\")\n",
    "        })\n",
    "\n",
    "    return metadata, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1c588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output_files(metadata, output_data, output_dir=\"output\"):\n",
    "\n",
    "    metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "    output_data_path = os.path.join(output_dir, \"output.csv\")\n",
    "    \n",
    "    metadata.to_csv(metadata_path, index=False)\n",
    "    output_data.to_csv(output_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9354fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, learning_rate, num_epochs, images, labels, num_sharpness_computations=100):\n",
    "    \n",
    "    optimizer.param_groups[0]['lr'] = learning_rate\n",
    "\n",
    "    model = model.to(device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    train_losses = np.empty(num_epochs)\n",
    "    sharps = np.full(num_epochs, np.nan)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"Learning Rate: {learning_rate}\")\n",
    "    print(f\"Number of Epochs: {num_epochs}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses[epoch] = loss.item()\n",
    "        \n",
    "        if (epoch + 1) % (num_epochs // num_sharpness_computations) == 0 or epoch == 0:\n",
    "            sharpness = compute_sharpness(model, criterion, images, labels, iters=10, \n",
    "                                    subsample=256)\n",
    "            sharps[epoch] = sharpness\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Sharpness: {sharpness}\")\n",
    "            \n",
    "    end_time = time.time()\n",
    "\n",
    "    metadata, output_data, = setup_output_files(\"output\")\n",
    "    model_id = metadata.shape[0] + 1\n",
    "    \n",
    "    metadata.loc[metadata.shape[0]] ={\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"train_time\": end_time - start_time,\n",
    "    }\n",
    "\n",
    "    output_data = pd.concat([output_data, pd.DataFrame({\n",
    "        \"model_id\": np.ones_like(train_losses) * model_id,\n",
    "        \"loss\": train_losses,\n",
    "        \"sharpness\": sharps\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    save_output_files(metadata, output_data, output_dir=\"output\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe1220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FullyConnectedNet\n",
      "Optimizer: SGD\n",
      "Learning Rate: 0.1\n",
      "Number of Epochs: 50\n",
      "Epoch [1/50], Loss: 0.1233, Sharpness: 16.111536026000977\n",
      "Epoch [5/50], Loss: 0.1006, Sharpness: 17.81403923034668\n",
      "Epoch [10/50], Loss: 0.0945, Sharpness: 17.709705352783203\n",
      "Epoch [15/50], Loss: 0.0909, Sharpness: 17.921512603759766\n",
      "Epoch [20/50], Loss: 0.0885, Sharpness: 18.23446273803711\n",
      "Epoch [25/50], Loss: 0.0867, Sharpness: 19.218605041503906\n",
      "Epoch [30/50], Loss: 0.0853, Sharpness: 14.314674377441406\n",
      "Epoch [35/50], Loss: 0.0843, Sharpness: 16.506935119628906\n",
      "Epoch [40/50], Loss: 0.0834, Sharpness: 15.81524658203125\n",
      "Epoch [45/50], Loss: 0.0826, Sharpness: 14.947366714477539\n",
      "Epoch [50/50], Loss: 0.0820, Sharpness: 15.68829345703125\n",
      "\n",
      "Model: FullyConnectedNet\n",
      "Optimizer: SGD\n",
      "Learning Rate: 0.04\n",
      "Number of Epochs: 50\n",
      "Epoch [1/50], Loss: 0.0819, Sharpness: 16.21432876586914\n",
      "Epoch [5/50], Loss: 0.0817, Sharpness: 14.808934211730957\n",
      "Epoch [10/50], Loss: 0.0815, Sharpness: 16.29054069519043\n",
      "Epoch [15/50], Loss: 0.0813, Sharpness: 15.72603702545166\n",
      "Epoch [20/50], Loss: 0.0811, Sharpness: 15.425413131713867\n",
      "Epoch [25/50], Loss: 0.0809, Sharpness: 15.832268714904785\n",
      "Epoch [30/50], Loss: 0.0807, Sharpness: 16.616884231567383\n",
      "Epoch [35/50], Loss: 0.0806, Sharpness: 14.792668342590332\n",
      "Epoch [40/50], Loss: 0.0804, Sharpness: 17.777610778808594\n",
      "Epoch [45/50], Loss: 0.0803, Sharpness: 14.76640796661377\n",
      "Epoch [50/50], Loss: 0.0801, Sharpness: 17.435976028442383\n",
      "\n",
      "Model: FullyConnectedNet\n",
      "Optimizer: SGD\n",
      "Learning Rate: 0.025\n",
      "Number of Epochs: 50\n",
      "Epoch [1/50], Loss: 0.0801, Sharpness: 15.635143280029297\n",
      "Epoch [5/50], Loss: 0.0800, Sharpness: 16.252470016479492\n",
      "Epoch [10/50], Loss: 0.0799, Sharpness: 15.545531272888184\n",
      "Epoch [15/50], Loss: 0.0798, Sharpness: 14.509133338928223\n",
      "Epoch [20/50], Loss: 0.0798, Sharpness: 15.810186386108398\n",
      "Epoch [25/50], Loss: 0.0797, Sharpness: 13.261618614196777\n",
      "Epoch [30/50], Loss: 0.0796, Sharpness: 14.648218154907227\n",
      "Epoch [35/50], Loss: 0.0795, Sharpness: 16.434701919555664\n",
      "Epoch [40/50], Loss: 0.0794, Sharpness: 15.665541648864746\n",
      "Epoch [45/50], Loss: 0.0794, Sharpness: 14.887605667114258\n",
      "Epoch [50/50], Loss: 0.0793, Sharpness: 17.462663650512695\n",
      "\n",
      "Model: FullyConnectedNet\n",
      "Optimizer: SGD\n",
      "Learning Rate: 0.01818181818181818\n",
      "Number of Epochs: 50\n",
      "Epoch [1/50], Loss: 0.0793, Sharpness: 18.138599395751953\n",
      "Epoch [5/50], Loss: 0.0792, Sharpness: 15.7060546875\n",
      "Epoch [10/50], Loss: 0.0792, Sharpness: 16.487037658691406\n",
      "Epoch [15/50], Loss: 0.0791, Sharpness: 17.10248565673828\n",
      "Epoch [20/50], Loss: 0.0791, Sharpness: 17.40312957763672\n",
      "Epoch [25/50], Loss: 0.0790, Sharpness: 13.517213821411133\n",
      "Epoch [30/50], Loss: 0.0790, Sharpness: 15.052671432495117\n",
      "Epoch [35/50], Loss: 0.0789, Sharpness: 15.660174369812012\n",
      "Epoch [40/50], Loss: 0.0789, Sharpness: 15.185012817382812\n",
      "Epoch [45/50], Loss: 0.0788, Sharpness: 15.821343421936035\n",
      "Epoch [50/50], Loss: 0.0788, Sharpness: 18.452896118164062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_size = np.prod(all_images.shape[1:])\n",
    "hidden_layer_1_size = 200\n",
    "hidden_layer_2_size = 200\n",
    "model = FullyConnectedNet(input_size, hidden_layer_1_size, hidden_layer_2_size, NUM_LABELS)\n",
    "\n",
    "learning_rates = [2/20, 2/50, 2/80, 2/110]\n",
    "num_epochs = 50\n",
    "    \n",
    "for lr in learning_rates:\n",
    "    train_model(model=model, \n",
    "                optimizer=torch.optim.SGD(model.parameters()), \n",
    "                criterion=nn.MSELoss(), \n",
    "                num_epochs=num_epochs,\n",
    "                learning_rate=lr,\n",
    "                images=images, \n",
    "                labels=labels,\n",
    "                num_sharpness_computations=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29947a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FullyConnectedNet.__init__() missing 4 required positional arguments: 'input_size', 'hidden_layer_1_size', 'hidden_layer_2_size', and 'num_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m images = images.to(device)\n\u001b[32m      2\u001b[39m labels = labels.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mFullyConnectedNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      5\u001b[39m criterion = nn.MSELoss()\n\u001b[32m      6\u001b[39m learning_rate = \u001b[32m0.1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: FullyConnectedNet.__init__() missing 4 required positional arguments: 'input_size', 'hidden_layer_1_size', 'hidden_layer_2_size', and 'num_labels'"
     ]
    }
   ],
   "source": [
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "model = FullyConnectedNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.1\n",
    "num_epochs = 5000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = np.empty(5000)\n",
    "sharps = np.empty(5000)\n",
    "\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}\")\n",
    "        sharpness = compute_sharpness(model, criterion, images, labels, iters=10, \n",
    "                                      subsample=256)\n",
    "        sharps.append(sharpness)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTraining completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Final loss: {train_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16525723",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpness_epochs = [20 * i for i in range(len(sharps))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create main plot with loss on left y-axis\n",
    "ax1 = plt.gca()\n",
    "line1 = ax1.plot(range(1, len(train_losses) + 1), train_losses, 'b-', linewidth=2, alpha=0.7, label='Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('MSE Loss', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Create second y-axis for sharpness\n",
    "ax2 = ax1.twinx()\n",
    "line2 = ax2.plot(sharpness_epochs, sharps, 'ro', linewidth=2, markersize=4, label='Sharpness')\n",
    "ax2.set_ylabel('Sharpness (Largest Eigenvalue)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Set y-axis to start at 0 for sharpness with 20% padding at top\n",
    "threshold = 2 / learning_rate\n",
    "ax2.set_ylim(bottom=0, top=threshold * 1.5)\n",
    "\n",
    "# Add horizontal line at 2/lr (theoretical threshold) on sharpness axis\n",
    "\n",
    "line3 = ax2.axhline(y=threshold, color='k', linestyle='--', linewidth=1.5, alpha=0.7, \n",
    "                    label=f'2/η = {threshold:.1f}')\n",
    "\n",
    "plt.title('Training Loss and Sharpness Over Time')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines = line1 + line2 + [line3]\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics (using filtered data)\n",
    "print(f\"\\nSharpness Statistics (excluding first 2 measurements):\")\n",
    "print(f\"Initial sharpness (3rd measurement): {sharps[0]:.4f}\")\n",
    "print(f\"Final sharpness: {sharps[-1]:.4f}\")\n",
    "print(f\"Maximum sharpness: {max(sharps):.4f}\")\n",
    "print(f\"Minimum sharpness: {min(sharps):.4f}\")\n",
    "print(f\"Average sharpness: {np.mean(sharps):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c2f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly for interactive plotting\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ec7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive Plotly version of the training plot\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add training loss line (primary y-axis)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(1, len(train_losses) + 1)),\n",
    "        y=train_losses,\n",
    "        mode='lines',\n",
    "        name='Training Loss',\n",
    "        line=dict(color='blue', width=3),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Epoch:</b> %{x}<br><b>Training Loss:</b> %{y:.6f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Add sharpness points (secondary y-axis)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sharpness_epochs,\n",
    "        y=sharps,\n",
    "        mode='markers+lines',\n",
    "        name='Sharpness',\n",
    "        line=dict(color='red', width=2),\n",
    "        marker=dict(color='red', size=8),\n",
    "        hovertemplate='<b>Epoch:</b> %{x}<br><b>Sharpness:</b> %{y:.6f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add theoretical threshold line (secondary y-axis)\n",
    "threshold = 2 / learning_rate\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[1, len(train_losses)],\n",
    "        y=[threshold, threshold],\n",
    "        mode='lines',\n",
    "        name=f'2/η = {threshold:.1f}',\n",
    "        line=dict(color='black', width=2, dash='dash'),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Theoretical Threshold:</b> %{y:.1f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Update layout and axes\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Training Loss and Sharpness Over Time (Interactive)',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 16}\n",
    "    },\n",
    "    xaxis_title='Epoch',\n",
    "    width=900,\n",
    "    height=600,\n",
    "    hovermode='x unified',\n",
    "    legend=dict(\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=1.02\n",
    "    ),\n",
    "    margin=dict(r=150)  # Add right margin for legend\n",
    ")\n",
    "\n",
    "# Set x-axis properties\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='lightgray',\n",
    "    zeroline=False\n",
    ")\n",
    "\n",
    "# Set y-axes properties\n",
    "fig.update_yaxes(\n",
    "    title_text=\"MSE Loss\", \n",
    "    secondary_y=False,\n",
    "    color='blue',\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='lightgray'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Sharpness (Largest Eigenvalue)\", \n",
    "    secondary_y=True,\n",
    "    color='red',\n",
    "    range=[0, threshold * 1.5],  # Match the matplotlib version\n",
    "    showgrid=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Print the same statistics as before\n",
    "print(f\"\\nSharpness Statistics:\")\n",
    "print(f\"Initial sharpness: {sharps[0]:.4f}\")\n",
    "print(f\"Final sharpness: {sharps[-1]:.4f}\")\n",
    "print(f\"Maximum sharpness: {max(sharps):.4f}\")\n",
    "print(f\"Minimum sharpness: {min(sharps):.4f}\")\n",
    "print(f\"Average sharpness: {np.mean(sharps):.4f}\")\n",
    "print(f\"Theoretical threshold (2/η): {threshold:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5148bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
