{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73471422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ded979",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 5000\n",
    "NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3ef949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc9865e-bec0-4f01-96ff-fe8724324a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0249c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:05<00:00, 28849065.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Normalize images\n",
    "all_images = torch.stack([dataset[i][0] for i in range(len(dataset))])\n",
    "all_labels = torch.tensor([dataset[i][1] for i in range(len(dataset))])\n",
    "\n",
    "cifar10_mean = np.array(all_images.mean(dim=(0, 2, 3)))\n",
    "cifar10_std = np.array(all_images.std(dim=(0, 2, 3)))\n",
    "\n",
    "mean_tensor = torch.tensor(cifar10_mean).view(1, 3, 1, 1)\n",
    "std_tensor = torch.tensor(cifar10_std).view(1, 3, 1, 1)\n",
    "\n",
    "normalized_images = (all_images - mean_tensor) / std_tensor\n",
    "\n",
    "# Subset first 5k samples\n",
    "images = normalized_images[:SAMPLE_SIZE]  # Use normalized images\n",
    "subset_labels = all_labels[:SAMPLE_SIZE]\n",
    "\n",
    "# Convert labels to one-hot encoding for MSE loss (CIFAR-10 has 10 classes)\n",
    "labels = torch.zeros(subset_labels.size(0), NUM_LABELS, device=subset_labels.device)\n",
    "labels.scatter_(1, subset_labels.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8b0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_1_size, hidden_layer_2_size, num_labels):\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, hidden_layer_1_size, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_layer_1_size, hidden_layer_2_size, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_layer_2_size, num_labels, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b928394",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_sharpness(model, criterion, images, labels,\n",
    "                      iters: int = 20, tol: float = 1e-3,\n",
    "                      subsample: int | None = 1024, damping: float = 0.0) -> float:\n",
    "    \"\"\"\n",
    "    Estimates λ_max(H) (sharpness) of the loss at current model parameters via\n",
    "    power iteration with Hessian–vector products (Pearlmutter trick).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model      : nn.Module (params require_grad=True)\n",
    "    criterion  : callable(logits, targets) -> scalar loss (mean reduction)\n",
    "    images     : tensor [N, ...] on correct device\n",
    "    labels     : tensor [N] on correct device\n",
    "    iters      : power-iteration steps (15–25 typical)\n",
    "    tol        : relative convergence tolerance\n",
    "    subsample  : if not None, randomly sample this many examples for speed\n",
    "    damping    : computes eigenvalues of (H + damping * I)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: estimated largest eigenvalue (sharpness)\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()  # stabilize stats (esp. BN/Dropout)\n",
    "\n",
    "    # ---- choose subset (for speed/memory) ----\n",
    "    if subsample is not None and images.size(0) > subsample:\n",
    "        idx = torch.randperm(images.size(0), device=images.device)[:subsample]\n",
    "        xb, yb = images[idx], labels[idx]\n",
    "    else:\n",
    "        xb, yb = images, labels\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    n = sum(p.numel() for p in params)\n",
    "    if n == 0:\n",
    "        if was_training: model.train()\n",
    "        return 0.0\n",
    "\n",
    "    # ---- forward with graph for second-order autodiff ----\n",
    "    # Important: no torch.no_grad() here\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    logits = model(xb)\n",
    "    loss = criterion(logits, yb)\n",
    "\n",
    "    # ∇ℓ with graph so we can differentiate it again\n",
    "    grads = torch.autograd.grad(loss, params, create_graph=True, retain_graph=True)\n",
    "    g_flat = torch.cat([gi.reshape(-1) for gi in grads])\n",
    "\n",
    "    # init v ~ unit vector\n",
    "    with torch.no_grad():\n",
    "        v = torch.randn(n, device=g_flat.device)\n",
    "        v /= (v.norm() + 1e-12)\n",
    "\n",
    "    lam_prev = None\n",
    "    for _ in range(iters):\n",
    "        # H v = ∇[(∇ℓ)·v]\n",
    "        gv = (g_flat * v).sum()\n",
    "        Hv_parts = torch.autograd.grad(gv, params, retain_graph=True)\n",
    "        Hv = torch.cat([h.reshape(-1) for h in Hv_parts])\n",
    "        if damping != 0.0:\n",
    "            Hv = Hv + damping * v\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Hv_norm = Hv.norm()\n",
    "            if Hv_norm == 0 or torch.isnan(Hv_norm):\n",
    "                lam = 0.0\n",
    "                break\n",
    "            v = Hv / (Hv_norm + 1e-12)\n",
    "            lam = torch.dot(v, Hv).item()\n",
    "\n",
    "            if lam_prev is not None:\n",
    "                if abs(lam - lam_prev) / (abs(lam_prev) + 1e-12) < tol:\n",
    "                    break\n",
    "            lam_prev = lam\n",
    "\n",
    "    # cleanup and restore mode\n",
    "    del grads, g_flat, logits, loss\n",
    "    if was_training: model.train()\n",
    "    return float(lam_prev if lam_prev is not None else lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314e88d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def setup_output_files(output_dir=\"output\"): \n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "    output_data_path = os.path.join(output_dir, \"output.csv\")\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "            metadata = pd.read_csv(metadata_path)\n",
    "    else:\n",
    "        metadata = pd.DataFrame({\n",
    "            \"model_id\": pd.Series(dtype=\"int\"),\n",
    "            \"model_type\": pd.Series(dtype=\"str\"),\n",
    "            \"optimizer\": pd.Series(dtype=\"str\"),\n",
    "            \"learning_rate\": pd.Series(dtype=\"float\"),\n",
    "            \"num_epochs\": pd.Series(dtype=\"int\"),\n",
    "            \"train_time\": pd.Series(dtype=\"float\")\n",
    "        })\n",
    "\n",
    "    if os.path.exists(output_data_path):\n",
    "        output_data = pd.read_csv(output_data_path)\n",
    "    else:\n",
    "        output_data = pd.DataFrame({\n",
    "            \"model_id\": pd.Series(dtype=\"int\"),\n",
    "            \"loss\": pd.Series(dtype=\"float\"),\n",
    "            \"sharpness\": pd.Series(dtype=\"float\")\n",
    "        })\n",
    "\n",
    "    return metadata, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1c588a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_output_files(metadata, output_data, output_dir=\"output\"):\n",
    "\n",
    "    metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "    output_data_path = os.path.join(output_dir, \"output.csv\")\n",
    "    \n",
    "    metadata.to_csv(metadata_path, index=False)\n",
    "    output_data.to_csv(output_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d9354fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, learning_rate, num_epochs, images, labels, num_sharpness_computations=100):\n",
    "    \n",
    "    optimizer.param_groups[0]['lr'] = learning_rate\n",
    "\n",
    "    model = model.to(device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    train_losses = np.empty(num_epochs)\n",
    "    sharps = np.full(num_epochs, np.nan)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "    print(f\"Learning Rate: {learning_rate}\")\n",
    "    print(f\"Number of Epochs: {num_epochs}\")\n",
    "    if model.__class__.__name__ == 'SGD': \n",
    "        print(f\"Momentum: {optimizer.defaults['momentum']}\")\n",
    "    else:\n",
    "        print(f\"Momentum: None\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses[epoch] = loss.item()\n",
    "        \n",
    "        if (epoch + 1) % (num_epochs // num_sharpness_computations) == 0 or epoch == 0:\n",
    "            sharpness = compute_sharpness(model, criterion, images, labels, iters=10, \n",
    "                                    subsample=256)\n",
    "            sharps[epoch] = sharpness\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Sharpness: {sharpness}\")\n",
    "            \n",
    "    end_time = time.time()\n",
    "\n",
    "    metadata, output_data, = setup_output_files(\"output\")\n",
    "    model_id = metadata.shape[0] + 1\n",
    "    \n",
    "    metadata.loc[metadata.shape[0]] ={\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"train_time\": end_time - start_time,\n",
    "        \"momentum\" : optimizer.defaults['momentum'] if model.__class__.__name__ == 'SGD' else 0\n",
    "    }\n",
    "\n",
    "    output_data = pd.concat([output_data, pd.DataFrame({\n",
    "        \"model_id\": np.ones_like(train_losses) * model_id,\n",
    "        \"loss\": train_losses,\n",
    "        \"sharpness\": sharps\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    save_output_files(metadata, output_data, output_dir=\"output\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fe1220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FullyConnectedNet\n",
      "Optimizer: SGD\n",
      "Learning Rate: 0.1\n",
      "Number of Epochs: 5000\n",
      "Momentum: None\n",
      "Epoch [1/5000], Loss: 0.1221, Sharpness: 15.711069107055664\n",
      "Epoch [50/5000], Loss: 0.0776, Sharpness: 11.312751770019531\n",
      "Epoch [100/5000], Loss: 0.0743, Sharpness: 11.772115707397461\n",
      "Epoch [150/5000], Loss: 0.0719, Sharpness: 13.58896255493164\n",
      "Epoch [200/5000], Loss: 0.0699, Sharpness: 12.72451114654541\n",
      "Epoch [250/5000], Loss: 0.0679, Sharpness: 11.672883033752441\n",
      "Epoch [300/5000], Loss: 0.0661, Sharpness: 15.431102752685547\n",
      "Epoch [350/5000], Loss: 0.0642, Sharpness: 15.693780899047852\n",
      "Epoch [400/5000], Loss: 0.0623, Sharpness: 16.218812942504883\n",
      "Epoch [450/5000], Loss: 0.0603, Sharpness: 19.035930633544922\n",
      "Epoch [500/5000], Loss: 0.0584, Sharpness: 22.969892501831055\n",
      "Epoch [550/5000], Loss: 0.0564, Sharpness: 22.77707290649414\n",
      "Epoch [600/5000], Loss: 0.0544, Sharpness: 27.613428115844727\n",
      "Epoch [650/5000], Loss: 0.0524, Sharpness: 29.211742401123047\n",
      "Epoch [700/5000], Loss: 0.0503, Sharpness: 31.375125885009766\n",
      "Epoch [750/5000], Loss: 0.0517, Sharpness: 27.82921600341797\n",
      "Epoch [800/5000], Loss: 0.0465, Sharpness: 33.47075653076172\n",
      "Epoch [850/5000], Loss: 0.0448, Sharpness: 32.82682800292969\n",
      "Epoch [900/5000], Loss: 0.0429, Sharpness: 26.09135627746582\n",
      "Epoch [950/5000], Loss: 0.0417, Sharpness: 28.618999481201172\n",
      "Epoch [1000/5000], Loss: 0.0403, Sharpness: 30.741397857666016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m momentum \u001b[38;5;129;01min\u001b[39;00m momentums:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m learning_rates:\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_sharpness_computations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sharpness_computations\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 30\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, learning_rate, num_epochs, images, labels, num_sharpness_computations)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 30\u001b[0m train_losses[epoch] \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (num_epochs \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_sharpness_computations) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m     sharpness \u001b[38;5;241m=\u001b[39m compute_sharpness(model, criterion, images, labels, iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m     34\u001b[0m                             subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = np.prod(all_images.shape[1:])\n",
    "hidden_layer_1_size = 200\n",
    "hidden_layer_2_size = 200\n",
    "model = FullyConnectedNet(input_size, hidden_layer_1_size, hidden_layer_2_size, NUM_LABELS)\n",
    "\n",
    "learning_rates = [2/20, 2/50, 2/80, 2/110]\n",
    "momentums = [0.6, 0.7, 0.8, 0.9]\n",
    "num_epochs = 5000\n",
    "num_sharpness_computations = 100\n",
    "    \n",
    "for momentum in momentums:\n",
    "    for lr in learning_rates:\n",
    "        train_model(model=model, \n",
    "                    optimizer=torch.optim.SGD(model.parameters(), momentum = momentum), \n",
    "                    criterion=nn.MSELoss(), \n",
    "                    num_epochs=num_epochs,\n",
    "                    learning_rate=lr,\n",
    "                    images=images, \n",
    "                    labels=labels,\n",
    "                    num_sharpness_computations=num_sharpness_computations\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16525723",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpness_epochs = [num_sharpness_computations * i for i in range(len(sharps))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create main plot with loss on left y-axis\n",
    "ax1 = plt.gca()\n",
    "line1 = ax1.plot(range(1, len(train_losses) + 1), train_losses, 'b-', linewidth=2, alpha=0.7, label='Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('MSE Loss', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Create second y-axis for sharpness\n",
    "ax2 = ax1.twinx()\n",
    "line2 = ax2.plot(sharpness_epochs, sharps, 'ro', linewidth=2, markersize=4, label='Sharpness')\n",
    "ax2.set_ylabel('Sharpness (Largest Eigenvalue)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Set y-axis to start at 0 for sharpness with 20% padding at top\n",
    "threshold = 2 / learning_rate\n",
    "ax2.set_ylim(bottom=0, top=threshold * 1.5)\n",
    "\n",
    "# Add horizontal line at 2/lr (theoretical threshold) on sharpness axis\n",
    "\n",
    "line3 = ax2.axhline(y=threshold, color='k', linestyle='--', linewidth=1.5, alpha=0.7, \n",
    "                    label=f'2/η = {threshold:.1f}')\n",
    "\n",
    "plt.title('Training Loss and Sharpness Over Time')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines = line1 + line2 + [line3]\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics (using filtered data)\n",
    "print(f\"\\nSharpness Statistics (excluding first 2 measurements):\")\n",
    "print(f\"Initial sharpness (3rd measurement): {sharps[0]:.4f}\")\n",
    "print(f\"Final sharpness: {sharps[-1]:.4f}\")\n",
    "print(f\"Maximum sharpness: {max(sharps):.4f}\")\n",
    "print(f\"Minimum sharpness: {min(sharps):.4f}\")\n",
    "print(f\"Average sharpness: {np.mean(sharps):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c2f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly for interactive plotting\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ec7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive Plotly version of the training plot\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add training loss line (primary y-axis)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(1, len(train_losses) + 1)),\n",
    "        y=train_losses,\n",
    "        mode='lines',\n",
    "        name='Training Loss',\n",
    "        line=dict(color='blue', width=3),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Epoch:</b> %{x}<br><b>Training Loss:</b> %{y:.6f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Add sharpness points (secondary y-axis)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sharpness_epochs,\n",
    "        y=sharps,\n",
    "        mode='markers+lines',\n",
    "        name='Sharpness',\n",
    "        line=dict(color='red', width=2),\n",
    "        marker=dict(color='red', size=8),\n",
    "        hovertemplate='<b>Epoch:</b> %{x}<br><b>Sharpness:</b> %{y:.6f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add theoretical threshold line (secondary y-axis)\n",
    "threshold = 2 / learning_rate\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[1, len(train_losses)],\n",
    "        y=[threshold, threshold],\n",
    "        mode='lines',\n",
    "        name=f'2/η = {threshold:.1f}',\n",
    "        line=dict(color='black', width=2, dash='dash'),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Theoretical Threshold:</b> %{y:.1f}<extra></extra>'\n",
    "    ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Update layout and axes\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Training Loss and Sharpness Over Time (Interactive)',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 16}\n",
    "    },\n",
    "    xaxis_title='Epoch',\n",
    "    width=900,\n",
    "    height=600,\n",
    "    hovermode='x unified',\n",
    "    legend=dict(\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=1.02\n",
    "    ),\n",
    "    margin=dict(r=150)  # Add right margin for legend\n",
    ")\n",
    "\n",
    "# Set x-axis properties\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='lightgray',\n",
    "    zeroline=False\n",
    ")\n",
    "\n",
    "# Set y-axes properties\n",
    "fig.update_yaxes(\n",
    "    title_text=\"MSE Loss\", \n",
    "    secondary_y=False,\n",
    "    color='blue',\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='lightgray'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Sharpness (Largest Eigenvalue)\", \n",
    "    secondary_y=True,\n",
    "    color='red',\n",
    "    range=[0, threshold * 1.5],  # Match the matplotlib version\n",
    "    showgrid=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Print the same statistics as before\n",
    "print(f\"\\nSharpness Statistics:\")\n",
    "print(f\"Initial sharpness: {sharps[0]:.4f}\")\n",
    "print(f\"Final sharpness: {sharps[-1]:.4f}\")\n",
    "print(f\"Maximum sharpness: {max(sharps):.4f}\")\n",
    "print(f\"Minimum sharpness: {min(sharps):.4f}\")\n",
    "print(f\"Average sharpness: {np.mean(sharps):.4f}\")\n",
    "print(f\"Theoretical threshold (2/η): {threshold:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5148bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
